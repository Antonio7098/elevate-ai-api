#!/usr/bin/env python3
"""
Test script for the LangChain-based Blueprint Editing Agent.
This uses the premium multi-agent system with structured output parsing.
"""

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from typing import Dict, Any

# Add the app directory to the path so we can import our modules
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
app_path = os.path.join(project_root, 'app')
print(f"Current directory: {current_dir}")
print(f"Project root: {project_root}")
print(f"App path: {app_path}")
print(f"App path exists: {os.path.exists(app_path)}")
sys.path.insert(0, app_path)

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

from app.core.premium.agents.blueprint_editing_agent import BlueprintEditingAgent

class LangChainBlueprintEditingTester:
    """Test class for the LangChain-based blueprint editing agent."""
    
    def __init__(self):
        """Initialize the tester with the LangChain agent."""
        print("ğŸš€ Initializing LangChain Blueprint Editing Agent Tester...")
        
        try:
            self.agent = BlueprintEditingAgent()
            print("âœ… LangChain agent initialized successfully")
        except Exception as e:
            print(f"âŒ Failed to initialize LangChain agent: {e}")
            raise
    
    async def test_blueprint_editing(self) -> bool:
        """Test blueprint editing with LangChain agent."""
        print("\nğŸ“ Test 1: Editing Blueprint for Clarity Improvement")
        print("-" * 50)
        
        start_time = time.time()
        
        try:
            # Mock blueprint data for testing
            blueprint_id = "test_blueprint_001"
            user_id = "test_user_001"
            edit_instruction = "Make the content clearer and more engaging for beginners"
            
            result = await self.agent.edit_content_agentically(
                content_id=blueprint_id,
                content_type="blueprint",
                edit_instruction=edit_instruction,
                user_id=user_id,
                edit_type="improve_clarity"
            )
            
            elapsed_time = time.time() - start_time
            
            if result["success"]:
                print(f"âœ… Blueprint editing completed in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Successfully edited blueprint using {result['edit_type']} approach")
                print(f"ğŸ¤” AI Reasoning: {result['reasoning'][:200]}...")
                print(f"ğŸ“‹ Edit Summary: {result['edit_plan'][:200]}...")
                
                # Show original vs edited content
                print(f"\nğŸ“ EDIT RESULT:")
                print(f"   Successfully edited blueprint using {result['edit_type']} approach")
                print(f"   Original content length: {len(str(result['original_content']))} characters")
                print(f"   Edited content length: {len(str(result['edited_content']))} characters")
                
                return True
            else:
                print(f"âŒ Blueprint editing failed in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Error editing blueprint: {result['error']}")
                return False
                
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Blueprint editing failed in {elapsed_time:.2f}s")
            print(f"ğŸ’¬ Message: Exception during blueprint editing: {str(e)}")
            return False
    
    async def test_primitive_editing(self) -> bool:
        """Test primitive editing with LangChain agent."""
        print("\nğŸ”¬ Test 2: Editing Knowledge Primitive for Clarity")
        print("-" * 50)
        
        start_time = time.time()
        
        try:
            primitive_id = "test_primitive_001"
            user_id = "test_user_001"
            edit_instruction = "Make the concept explanation clearer and add more examples"
            
            result = await self.agent.edit_content_agentically(
                content_id=primitive_id,
                content_type="primitive",
                edit_instruction=edit_instruction,
                user_id=user_id,
                edit_type="improve_clarity"
            )
            
            elapsed_time = time.time() - start_time
            
            if result["success"]:
                print(f"âœ… Primitive editing completed in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Successfully edited primitive using {result['edit_type']} approach")
                print(f"ğŸ¤” AI Reasoning: {result['reasoning'][:200]}...")
                print(f"ğŸ“‹ Edit Summary: {result['edit_plan'][:200]}...")
                
                # Show original vs edited content
                print(f"\nğŸ“ EDIT RESULT:")
                print(f"   Successfully edited primitive using {result['edit_type']} approach")
                print(f"   Original content length: {len(str(result['original_content']))} characters")
                print(f"   Edited content length: {len(str(result['edited_content']))} characters")
                
                return True
            else:
                print(f"âŒ Primitive editing failed in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Error editing primitive: {result['error']}")
                return False
                
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Primitive editing failed in {elapsed_time:.2f}s")
            print(f"ğŸ’¬ Message: Exception during primitive editing: {str(e)}")
            return False
    
    async def test_suggestions_generation(self) -> bool:
        """Test editing suggestions generation with LangChain agent."""
        print("\nğŸ’¡ Test 3: Generating Editing Suggestions")
        print("-" * 50)
        
        start_time = time.time()
        
        try:
            content_id = "test_content_001"
            user_id = "test_user_001"
            
            result = await self.agent.get_editing_suggestions_agentically(
                content_id=content_id,
                content_type="blueprint",
                user_id=user_id,
                suggestion_type="general"
            )
            
            elapsed_time = time.time() - start_time
            
            if result["success"]:
                print(f"âœ… Suggestions generated in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Generated editing suggestions successfully")
                print(f"ğŸ’¡ Suggestions: {result['suggestions'][:200]}...")
                return True
            else:
                print(f"âŒ Suggestions generation failed in {elapsed_time:.2f}s")
                print(f"ğŸ“Š Success: {result['success']}")
                print(f"ğŸ’¬ Message: Error generating suggestions: {result['error']}")
                return False
                
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Suggestions generation failed in {elapsed_time:.2f}s")
            print(f"ğŸ’¬ Message: Exception during suggestions generation: {str(e)}")
            return False
    
    async def test_granular_editing(self) -> bool:
        """Test granular editing operations with LangChain agent."""
        print("\nğŸ”§ Test 4: Executing Granular Edit Operations")
        print("-" * 50)
        
        start_time = time.time()
        
        try:
            # Test adding a new section
            content = "Sample blueprint content with sections"
            parameters = {"section_name": "Advanced Topics", "content": "Advanced concepts and applications"}
            
            result = await self.agent.execute_granular_edit(
                edit_type="add_section",
                content=content,
                parameters=parameters
            )
            
            elapsed_time = time.time() - start_time
            
            if "successfully" in result.lower():
                print(f"âœ… Granular edit completed in {elapsed_time:.2f}s")
                print(f"ğŸ’¬ Message: {result}")
                return True
            else:
                print(f"âŒ Granular edit failed in {elapsed_time:.2f}s")
                print(f"ğŸ’¬ Message: {result}")
                return False
                
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ Granular edit failed in {elapsed_time:.2f}s")
            print(f"ğŸ’¬ Message: Exception during granular edit: {str(e)}")
            return False
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all tests and return comprehensive results."""
        print("ğŸ§ª LangChain Blueprint Editing Agent Test Suite")
        print("=" * 60)
        print("ğŸš€ Starting LangChain-based editing tests...")
        print("âš ï¸  This will make actual API calls to Gemini 2.5 Flash")
        print("ğŸ’° Be aware of potential costs and rate limits")
        print("=" * 60)
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "tests_run": 0,
            "tests_passed": 0,
            "tests_failed": 0,
            "total_time": 0,
            "test_results": {}
        }
        
        start_time = time.time()
        
        # Test 1: Blueprint editing
        test_result = await self.test_blueprint_editing()
        results["test_results"]["blueprint_editing"] = test_result
        results["tests_run"] += 1
        if test_result:
            results["tests_passed"] += 1
        else:
            results["tests_failed"] += 1
        
        # Test 2: Primitive editing
        test_result = await self.test_primitive_editing()
        results["test_results"]["primitive_editing"] = test_result
        results["tests_run"] += 1
        if test_result:
            results["tests_passed"] += 1
        else:
            results["tests_failed"] += 1
        
        # Test 3: Suggestions generation
        test_result = await self.test_suggestions_generation()
        results["test_results"]["suggestions_generation"] = test_result
        results["tests_run"] += 1
        if test_result:
            results["tests_passed"] += 1
        else:
            results["tests_failed"] += 1
        
        # Test 4: Granular editing
        test_result = await self.test_granular_editing()
        results["test_results"]["granular_editing"] = test_result
        results["tests_run"] += 1
        if test_result:
            results["tests_passed"] += 1
        else:
            results["tests_failed"] += 1
        
        results["total_time"] = time.time() - start_time
        
        # Print summary
        print("\n" + "=" * 60)
        if results["tests_failed"] == 0:
            print("ğŸ‰ ALL LANGCHAIN TESTS PASSED!")
        else:
            print(f"âŒ SOME LANGCHAIN TESTS FAILED!")
        print("=" * 60)
        print(f"ğŸ“Š Test Results: {results['tests_passed']}/{results['tests_run']} tests passed")
        print(f"â±ï¸  Total Time: {results['total_time']:.2f}s")
        
        if results["tests_failed"] > 0:
            print("âŒ Failed tests - check error messages above")
        else:
            print("âœ… All tests completed successfully")
        
        return results

async def main():
    """Main test execution function."""
    try:
        tester = LangChainBlueprintEditingTester()
        results = await tester.run_all_tests()
        
        # Save results to file
        with open("langchain_test_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ“ Test results saved to: langchain_test_results.json")
        
    except Exception as e:
        print(f"âŒ Test execution failed: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
