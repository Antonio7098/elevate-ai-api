#!/usr/bin/env python3
"""
Simple RAG Test - Just test RAG search and response generation
"""

import asyncio
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv(override=True)

# Add app to path
import sys
sys.path.append('.')

async def test_simple_rag():
    """Simple test of RAG pipeline"""
    
    print("ğŸ¯ SIMPLE RAG PIPELINE TEST")
    print("=" * 40)
    
    try:
        # Check environment
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ No GOOGLE_API_KEY found")
            return False
        
        print(f"âœ… API key found: {api_key[:10]}...")
        
        # Initialize embedding service
        from app.core.embeddings import initialize_embedding_service
        initialize_embedding_service("google", api_key=api_key)
        print("âœ… Embedding service initialized")
        
        # Test RAG search
        from app.core.rag_search import RAGSearchService, RAGSearchRequest
        
        search_service = RAGSearchService()
        search_request = RAGSearchRequest(
            query="What is machine learning?",
            top_k=3,
            similarity_threshold=0.6
        )
        
        print("ğŸ” Testing RAG search...")
        search_response = await search_service.search(search_request)
        
        print(f"âœ… RAG search completed - found {len(search_response.results)} results")
        
        if search_response.results:
            for i, result in enumerate(search_response.results, 1):
                print(f"   ğŸ“– Result {i}: {result.content[:60]}...")
        
        # Test Gemini directly
        print("ğŸ¤– Testing Gemini API directly...")
        from app.services.gemini_service import GeminiService
        
        gemini = GeminiService()
        if gemini.mock_mode:
            print("âŒ Gemini is in mock mode!")
            return False
        
        # Create a simple prompt with retrieved context
        if search_response.results:
            context_text = "\n".join([f"- {r.content[:100]}" for r in search_response.results[:2]])
            prompt = f"""Based on the following retrieved knowledge:

{context_text}

Please answer this question: What is machine learning?

Provide a concise answer based on the context above."""
        else:
            prompt = "What is machine learning? Provide a concise explanation."
        
        print("ğŸ“ Generating response...")
        response = await gemini.generate_response(prompt)
        
        print("âœ… Response generated!")
        print()
        print("ğŸ¯ RESULTS:")
        print("-" * 40)
        print(f"Query: What is machine learning?")
        print(f"Retrieved: {len(search_response.results)} knowledge pieces")
        print()
        print("ğŸ¤– AI Response:")
        print(response)
        print("-" * 40)
        
        return True
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_simple_rag())
    if success:
        print("\nğŸš€ RAG PIPELINE VALIDATION SUCCESSFUL!")
        print("âœ… Environment loading working")
        print("âœ… Embedding service working") 
        print("âœ… RAG search working")
        print("âœ… Gemini API working")
        print("âœ… Context-aware responses possible")
    else:
        print("\nğŸ’¥ RAG PIPELINE NEEDS FIXES")
