### Gemini 2.5 Pro
Gemini 2.5 Pro is our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-pro)

#### Model details

```
gemini-2.5-pro
```

Inputs
Audio, images, video, text, and PDF
Output
Text
[*]
Input token limit
1,048,576
Output token limit
65,536
Structured outputs
Supported
Caching
Supported
Function calling
Supported
Code execution
Supported
Search grounding
Supported
Image generation
Not supported
Audio generation
Not supported
Live API
Not supported
Thinking
Supported
Batch Mode
Supported
[model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini)
- Stable: gemini-2.5-pro

```
Stable: gemini-2.5-pro
```

### Gemini 2.5 Flash
Our best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash)

#### Model details

```
models/gemini-2.5-flash
```

Inputs
Text, images, video, audio
Output
Text
[*]
Input token limit
1,048,576
Output token limit
65,536
Audio generation
Not supported
Caching
Supported
Code execution
Supported
Function calling
Supported
Image generation
Not supported
Search grounding
Supported
Structured outputs
Supported
Thinking
Supported
Batch Mode
Supported
[model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini)
- Stable: gemini-2.5-flash
- Preview: gemini-2.5-flash-preview-05-20

```
gemini-2.5-flash
```


```
gemini-2.5-flash-preview-05-20
```

### Gemini 2.5 Flash-Lite
A Gemini 2.5 Flash model optimized for cost-efficiency and high throughput.
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite)

#### Model details

```
models/gemini-2.5-flash-lite
```

Inputs
Text, image, video, audio, PDF
Output
Text
[*]
Input token limit
1,048,576
Output token limit
65,536
Structured outputs
Supported
Caching
Supported
Function calling
Supported
Code execution
Supported
URL Context
Supported
Search grounding
Supported
Image generation
Not supported
Audio generation
Not supported
Live API
Not supported
Thinking
Supported
Batch mode
Supported
[model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini)
- Stable: gemini-2.5-flash-lite
- Preview: gemini-2.5-flash-lite-06-17

```
gemini-2.5-flash-lite
```


```
gemini-2.5-flash-lite-06-17
```

### Gemini 2.5 Flash Live
The Gemini 2.5 Flash Live model works with the Live API to enable low-latency bidirectional voice and video interactions with Gemini. The model can process text, audio, and video input, and it can provide text and audio output.
[Try in Google AI Studio](https://aistudio.google.com?model=gemini-live-2.5-flash-preview)

#### Model details

```
models/gemini-live-2.5-flash-preview
```

Inputs
Audio, video, and text
Output
Text, and audio
[*]
Input token limit
1,048,576
Output token limit
8,192
Structured outputs
Supported
Tuning
Not supported
Function calling
Supported
Code execution
Supported
Search
Supported
Image generation
Not supported
Audio generation
Supported
Thinking
Not supported
[model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini)
- Preview: gemini-live-2.5-flash-preview

```
gemini-live-2.5-flash-preview
```