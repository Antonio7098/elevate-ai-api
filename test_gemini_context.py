#!/usr/bin/env python3
"""
Test Gemini Context-Aware Responses
"""

import asyncio
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv(override=True)

# Add app to path
import sys
sys.path.append('.')

async def test_gemini_context():
    """Test that Gemini uses provided context"""
    
    print("ğŸ¯ GEMINI CONTEXT-AWARE RESPONSE TEST")
    print("=" * 50)
    
    try:
        # Check API key
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ No GOOGLE_API_KEY found")
            return False
        
        print(f"âœ… API key loaded: {api_key[:10]}...")
        
        # Initialize Gemini service
        from app.services.gemini_service import GeminiService
        
        gemini = GeminiService()
        
        if gemini.mock_mode:
            print("âŒ Gemini is in mock mode! Cannot test real API.")
            return False
        
        print("âœ… Gemini service initialized (not in mock mode)")
        
        # Test 1: Response WITHOUT context (general knowledge)
        print("\nğŸ§ª Test 1: General knowledge response")
        print("-" * 30)
        
        general_prompt = "What is machine learning?"
        general_response = await gemini.generate_response(general_prompt)
        
        print("ğŸ“ General response:")
        print(general_response[:150] + "...")
        
        # Test 2: Response WITH specific context
        print("\nğŸ§ª Test 2: Context-aware response")  
        print("-" * 30)
        
        # Simulate retrieved context from our Pinecone index
        context_prompt = """Based on the following knowledge retrieved from our database:

RETRIEVED CONTEXT:
- "Machine Learning is a subset of Artificial Intelligence"
- "Machine Learning Model Development Steps: 1. Define problem and collect data, 2. Preprocess and clean data, 3. Choose appropriate algorithm, 4. Train model on training data, 5. Evaluate model performance, 6. Deploy and monitor model"
- "Common machine learning algorithms include supervised learning, unsupervised learning, and reinforcement learning"

Please answer this question using the context above: What is machine learning?

Focus on the information provided in the retrieved context."""

        context_response = await gemini.generate_response(context_prompt)
        
        print("ğŸ“ Context-aware response:")
        print(context_response[:150] + "...")
        
        # Analysis
        print("\nğŸ§ ANALYSIS:")
        print("-" * 30)
        
        # Check if context response mentions specific details from our context
        context_lower = context_response.lower()
        general_lower = general_response.lower()
        
        context_indicators = []
        if "subset" in context_lower and "artificial intelligence" in context_lower:
            context_indicators.append("âœ… Mentions ML as subset of AI (from context)")
        
        if "steps" in context_lower or "development" in context_lower:
            context_indicators.append("âœ… Mentions development steps (from context)")
            
        if "supervised" in context_lower and "unsupervised" in context_lower:
            context_indicators.append("âœ… Mentions algorithm types (from context)")
        
        print(f"ğŸ“Š Context indicators found: {len(context_indicators)}")
        for indicator in context_indicators:
            print(f"   {indicator}")
        
        # Final assessment
        if len(context_indicators) >= 2:
            print("\nğŸ‰ SUCCESS: Gemini is using retrieved context!")
            print("âœ… Context-aware responses are working")
            return True
        elif len(context_indicators) >= 1:
            print("\nâš ï¸ PARTIAL: Some context usage detected")
            print("ğŸ” May need prompt engineering improvements")
            return True
        else:
            print("\nâŒ CONCERN: Limited context usage detected")
            print("ğŸ” May need to improve context formatting")
            return False
            
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_gemini_context())
    if success:
        print("\nğŸš€ GEMINI CONTEXT-AWARE RESPONSES VALIDATED!")
        print("âœ… RAG pipeline can generate context-aware responses")
        print("âœ… Ready for production use")
    else:
        print("\nğŸ’¥ GEMINI CONTEXT USAGE NEEDS IMPROVEMENT")
